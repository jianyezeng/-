## 自动调整学习速率

### 不变的learning rate存在的问题：

1. 如果learning rate比较大，可能无论如何都无法到达最低点，而是在最低点旁左右横条

   ![rate large](https://zjyimage.oss-cn-beijing.aliyuncs.com/202305052114801.PNG)

2. 如果learning rate比较小，问题1得到一定程度的解决，但是当grandient比较大时，移动的还比较快，当grandient比较小时，就会出现移动的很慢的情况。

![rate](https://zjyimage.oss-cn-beijing.aliyuncs.com/202305052114802.PNG)

### Root Mean Square与RMSProp

![02](https://zjyimage.oss-cn-beijing.aliyuncs.com/202305052114803.PNG)

引入一个新的参数$\sigma_i^t$, 这样可以实现learning rate自动调整的目的，但这样存在一个问题，那就是最开始移动的g与最近移动的g对于$\sigma$的大小的影响是相同的，这样learning rate对于g变化的反应是比较缓慢的，那么做到让learning rate更快地对g变化做出反应呢？我们可以使用RMSProp

![sig](https://zjyimage.oss-cn-beijing.aliyuncs.com/202305052114804.PNG)

### learning Rate Scheduling

![yz](https://zjyimage.oss-cn-beijing.aliyuncs.com/202305052114805.PNG)

在进入grandient较小的区域后，在纵轴方向累计了很多很小的$\sigma$,当累计到一定程度后，可能就会出现如图所示的情况。为了解决这一问题，可以使用learning Rate Scheduling

![？？](https://zjyimage.oss-cn-beijing.aliyuncs.com/202305052114806.PNG)

即让$\eta$也随移动而变化，如何变化呢？有两种方案：

- learning rate decay：即从大到小，
- warm up：先从小增大到一定程度，再减小，原因：刚开始的$\sigma$是不准确的，因此先缓慢移动，等$\sigma$达到一定的准确程度，再继续快速移动.

### 自动更新学习速率+Momentum

![s+m](https://zjyimage.oss-cn-beijing.aliyuncs.com/202305052114807.PNG)

在$\sigma$的更新过程中，是与方向无关的（取了平方），因此与momentum不会抵消。
